{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!pip3 install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7df814",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = {}\n",
    "course = pd.read_csv(\"../csv/Course.csv\")\n",
    "content = pd.read_csv(\"../csv/Content.csv\")\n",
    "content_id = pd.read_csv(\"../csv/content_with_doid.csv\")\n",
    "content_id = content_id.rename(columns={\"video_code\": \"content_code\", \"doID\":\"content_do_id\"})\n",
    "module = pd.read_csv(\"../csv/module.csv\")\n",
    "all_df[\"course\"] = course\n",
    "all_df[\"content\"] = content\n",
    "all_df[\"content_id\"] = content_id\n",
    "all_df[\"module\"] = module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in course_name and course_code using forward fill\n",
    "content[['course_name', 'course_code']] = content[['course_name', 'course_code']].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0855ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove rows where content_name contains 'QUIZ'\n",
    "def remove_quiz(df):\n",
    "    return df[~df['content_name'].str.contains('QUIZ', na=False)]\n",
    "\n",
    "# Apply the function to the content dataframe\n",
    "# content = remove_quiz(content)\n",
    "# print(\"Content DataFrame after removing QUIZ rows:\")\n",
    "module = module[module.columns[0:5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_id.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract module_code from content_code using different approaches based on content\n",
    "def extract_module_code(code):\n",
    "    if 'MQ' in code:\n",
    "        # For content codes containing MQ, just remove MQ\n",
    "        return code.replace('MQ', '')\n",
    "    else:\n",
    "        # For other content codes, extract the module code pattern\n",
    "        import re\n",
    "        match = re.search(r'^(FMPS_MC\\d{3}_\\d{2})', code)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return code\n",
    "\n",
    "# Apply the extraction function to create module_code column\n",
    "content['module_code'] = content['content_code'].apply(extract_module_code)\n",
    "content['module_code'] = content['module_code'].astype(str)\n",
    "module['module_code'] = module['module_code'].astype(str)\n",
    "merged = pd.merge(content, module, on='module_code', how='left')\n",
    "merged = merged[['course_code', 'course_name', 'module_code', 'module_name', 'content_code', 'content_name',\n",
    "       'framework_languages_x', 'content_url', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(merged, content_id, on='content_code', how='left')\n",
    "all_df[\"merged\"] = merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[['course_code', 'course_name', 'module_code', 'module_name',\n",
    "       'content_code', 'content_name', 'framework_languages_x',\n",
    "    'content_url_x', 'content_do_id']].rename(columns={'content_url_x': 'content_url', 'framework_languages_x': 'framework_languages'})\n",
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!pip3 install requests\n",
    "# !!pip3 install pprint\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "url = \"https://dev-fmps.sunbirded.org/api/composite/v1/search\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"request\": {\n",
    "    \"filters\": {\n",
    "      \"code\": [\n",
    "        \"FMPS_MC003_MQ01\",\n",
    "        \"FMPS_MC003_MQ02\",\n",
    "        \"FMPS_MC003_MQ03\",\n",
    "        \"FMPS_MC003_MQ04\",\n",
    "        \"FMPS_MC003_MQ05\",\n",
    "        \"FMPS_MC003_MQ06\",\n",
    "        \"FMPS_MC004_MQ01\",\n",
    "        \"FMPS_MC004_MQ02\",\n",
    "        \"FMPS_MC004_MQ03\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "})\n",
    "headers = {\n",
    "  'Accept': 'application/json',\n",
    "  'Content-Type': 'application/json',\n",
    "  'X-Channel-Id': '01429195271738982411',\n",
    "  'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJhcGlfYWRtaW4ifQ.-qfZEwBAoHFhxNqhGq7Vy_SNVcwB1AtMX8xbiVHF5FQ',\n",
    "  'x-authenticated-user-token': 'eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJab3p3U212UUFXTkRXZmIzQm1kNi1abi1JbFotd3RIaHd3OEdMTVpObGlFIn0.eyJqdGkiOiIwODI5NDA4NS1iNzU3LTQ2NzktOGM1My00YTY2NmViNDRiZTUiLCJleHAiOjE3NDcxNjI5NzQsIm5iZiI6MCwiaWF0IjoxNzQ3MTE5Nzc0LCJpc3MiOiJodHRwczovL2djcC1mbXBzLnN1bmJpcmRlZC5vcmcvYXV0aC9yZWFsbXMvc3VuYmlyZCIsImF1ZCI6ImFjY291bnQiLCJzdWIiOiJmOmNhc3NhbmRyYWZlZGVyYXRpb25pZDpjYmY1NzNlNC03MWJlLTRiOTUtYjdjNy01NDM5Mzk3ZDZjMDciLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJkaXJlY3QtZ3JhbnQiLCJhdXRoX3RpbWUiOjAsInNlc3Npb25fc3RhdGUiOiJlODk2MTkyNi1kOTEwLTQzMDUtOTc5MS04ZmZmNTNhYWFlYmMiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbImh0dHBzOi8vZ2NwLWZtcHMuc3VuYmlyZGVkLm9yZyJdLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6IkNvbnRlbnQgQ3JlYXRvciBGTVBTIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiY29udGVudGNyZWF0b3ItZm1wcyIsImdpdmVuX25hbWUiOiJDb250ZW50IENyZWF0b3IiLCJmYW1pbHlfbmFtZSI6IkZNUFMiLCJlbWFpbCI6ImNvKioqKioqKioqKioqKioqKioqQHlvcG1haWwuY29tIn0.ZSbH35ImBofm0Cs8BrGTJUa9fTG18kyAdYyEIgCWTcEzAZtUyzPaosWappn9K0s8dGsjuVQPUbshkB1nRgPt5T4S9Wl8ISZ0sRp2pnWNcA7I_bQCzy_PhG-e8ZOC42NBskiZOIxFzB8MhzqYRhsxfQRdUmInpHIW0fYxIoiUPbQZ6bZb0j5GDMqshuHurrM1hfYpcKjnsx8_h3B43nn4G3YvCktSHVO6YxQC1KcHozPgtddN-aLo525v8OVfopC5lF_9KNjE6IEh5XClyojGXEQ6hr1fvMWNoFcz72D3Ajo2A2KbaNXhRbBF1YwOy9CyG4t68dsd-R35aTu0oyev6w'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "# pprint.pprint(json.loads(response.text))\n",
    "final_data = []\n",
    "\n",
    "for i in json.loads(response.text)['result']['content']:\n",
    "    final_data.append({\n",
    "        'content_code': i['code'],\n",
    "        'content_do_id': i['identifier']\n",
    "    })\n",
    "quiz_df = pd.DataFrame(final_data)\n",
    "all_df[\"quiz_df\"] = quiz_df\n",
    "merged_with_quiz = pd.merge(merged, quiz_df, on='content_code', how='left')\n",
    "\n",
    "\n",
    "# Examine merged_with_quiz columns\n",
    "print(\"Columns in merged_with_quiz:\")\n",
    "print(merged_with_quiz.columns.tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if we have duplicate content_do_id columns after the merge\n",
    "do_id_cols = [col for col in merged_with_quiz.columns if 'content_do_id' in col]\n",
    "print(f\"\\nDO ID columns: {do_id_cols}\")\n",
    "merged_with_quiz.sample(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if we have duplicate content_do_id columns after the merge\n",
    "do_id_cols = [col for col in merged_with_quiz.columns if 'content_do_id' in col]\n",
    "\n",
    "# If we have two columns (content_do_id_x and content_do_id_y), merge them\n",
    "if len(do_id_cols) == 2:\n",
    "    # Combine content_do_id columns, taking non-NaN values from either column\n",
    "    merged_with_quiz['content_do_id'] = merged_with_quiz[do_id_cols[0]].combine_first(merged_with_quiz[do_id_cols[1]])\n",
    "    \n",
    "    # Drop the original columns\n",
    "    merged_with_quiz = merged_with_quiz.drop(columns=do_id_cols)\n",
    "    \n",
    "    print(f\"Merged {do_id_cols[0]} and {do_id_cols[1]} into a new 'content_do_id' column\")\n",
    "elif 'content_do_id' in merged_with_quiz.columns:\n",
    "    print(\"Already have a unified content_do_id column\")\n",
    "else:\n",
    "    print(\"No content_do_id columns found to merge\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"\\nColumn names after processing:\")\n",
    "print(merged_with_quiz.columns.tolist())\n",
    "merged_with_quiz.sample(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save merged DataFrame with combined content_do_id to CSV\n",
    "output_csv_path = 'merged_with_combined_ids.csv'\n",
    "merged_with_quiz.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Saved merged DataFrame with combined content_do_id to {output_csv_path}\")\n",
    "\n",
    "# Add to our dictionary of dataframes for reference\n",
    "all_df[\"merged_with_quiz\"] = merged_with_quiz\n",
    "\n",
    "# Display row and column counts\n",
    "print(f\"Final DataFrame shape: {merged_with_quiz.shape} (rows × columns)\")\n",
    "print(f\"Non-null content_do_id values: {merged_with_quiz['content_do_id'].count() if 'content_do_id' in merged_with_quiz.columns else 'N/A'}\")\n",
    "\n",
    "# Count NaN values in critical columns\n",
    "for col in ['content_code', 'content_do_id', 'module_code']:\n",
    "    if col in merged_with_quiz.columns:\n",
    "        null_count = merged_with_quiz[col].isna().sum()\n",
    "        print(f\"NaN values in {col}: {null_count} ({null_count/len(merged_with_quiz)*100:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"Column {col} not found in DataFrame\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged_with_quiz.to_json(\"out.json\",orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b688f",
   "metadata": {},
   "source": [
    "# Creating Course Hierarchy\n",
    "\n",
    "Now let's create a hierarchical structure from the out.json file following the pattern: course -> module -> content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def create_course_hierarchy(file_path):\n",
    "    # Read the JSON file line by line\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Parse each line as JSON\n",
    "    json_objects = [json.loads(line) for line in lines if line.strip()]\n",
    "    \n",
    "    # Create the hierarchy structure\n",
    "    hierarchy = {}\n",
    "    \n",
    "    # Process each JSON object\n",
    "    for obj in json_objects:\n",
    "        course_code = obj['course_code']\n",
    "        course_name = obj['course_name']\n",
    "        module_code = obj['module_code']\n",
    "        module_name = obj['module_name']\n",
    "        content_code = obj['content_code']\n",
    "        \n",
    "        # Initialize course if it doesn't exist\n",
    "        if course_code not in hierarchy:\n",
    "            hierarchy[course_code] = {\n",
    "                'name': course_name,\n",
    "                'modules': {}\n",
    "            }\n",
    "        \n",
    "        # Initialize module if it doesn't exist\n",
    "        if module_code not in hierarchy[course_code]['modules']:\n",
    "            hierarchy[course_code]['modules'][module_code] = {\n",
    "                'name': module_name,\n",
    "                'contents': []\n",
    "            }\n",
    "        \n",
    "        # Add content to the module\n",
    "        hierarchy[course_code]['modules'][module_code]['contents'].append({\n",
    "            'code': content_code,\n",
    "            'name': obj['content_name'],\n",
    "            'url': obj['content_url'],\n",
    "            'doId': obj['content_do_id'],\n",
    "            'languages': obj['framework_languages']\n",
    "        })\n",
    "    \n",
    "    return hierarchy\n",
    "\n",
    "# File path\n",
    "file_path = 'out.json'\n",
    "\n",
    "# Create hierarchy\n",
    "hierarchy = create_course_hierarchy(file_path)\n",
    "\n",
    "# Print sample to verify\n",
    "course_keys = list(hierarchy.keys())\n",
    "if course_keys:\n",
    "    sample_course = hierarchy[course_keys[0]]\n",
    "    print(f\"Sample course: {sample_course['name']}\")\n",
    "    \n",
    "    module_keys = list(sample_course['modules'].keys())\n",
    "    if module_keys:\n",
    "        sample_module = sample_course['modules'][module_keys[0]]\n",
    "        print(f\"Sample module: {sample_module['name']}\")\n",
    "        print(f\"Number of contents: {len(sample_module['contents'])}\")\n",
    "        if sample_module['contents']:\n",
    "            print(f\"Sample content: {sample_module['contents'][0]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define descriptions for known courses\n",
    "course_descriptions = {\n",
    "    \"FMPS_C003\": \"التربية الوالدية مفهوم يشمل الأسرة والمدرسة كمؤسستين اجتماعيتين تسهمان في تنشئة الطفل. تهدف إلى تحقيق التكامل بين دور الوالدين والمربي في تربية الطفل من خلال دعم القيم والسلوكيات الإيجابية، بما يعزز الجوانب النفسية والاجتماعية والمعرفية للطفل ويسهم في بناء مجتمع متماسك وواعٍ.\",\n",
    "    \"FMPS_C004\": \"نظريات التعلم هي إطار نظري يفسر كيفية اكتساب المعرفة وتطوير المهارات. تهدف هذه المصوغة إلى تمكين المربي من فهم النظريات المختلفة للتعلم وتطبيقاتها في الممارسة التربوية، مما يساعده على تصميم وتنفيذ أنشطة تعليمية فعالة تناسب احتياجات المتعلمين وأنماط تعلمهم المختلفة.\"\n",
    "}\n",
    "\n",
    "# Function to get a default description if not found in dictionary\n",
    "def get_description(course_code, course_name):\n",
    "    if course_code in course_descriptions:\n",
    "        return course_descriptions[course_code]\n",
    "    return f\"مصوغة {course_name} تهدف إلى تزويد المربي بالكفايات والمعارف الضرورية لتحسين الممارسة التربوية وتعزيز جودة التعليم الأولي.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform hierarchy into courses.json format\n",
    "courses_data = []\n",
    "\n",
    "for course_code, course_info in hierarchy.items():\n",
    "    course_name = course_info['name']\n",
    "    \n",
    "    # Get appropriate description for this course\n",
    "    course_description = get_description(course_code, course_name)\n",
    "    \n",
    "    # Create a course object with the required fields\n",
    "    course_obj = {\n",
    "        \"name\": course_name,\n",
    "        \"code\": course_code,\n",
    "        \"description\": course_description,\n",
    "        \"createdBy\": \"927c2094-987f-4e8f-8bd5-8bf93e3d2e8a\",\n",
    "        \"organisation\": \"FMPS Org\",\n",
    "        \"createdFor\": [\"01429195271738982411\"],\n",
    "        \"mimeType\": \"application/vnd.ekstep.content-collection\",\n",
    "        \"resourceType\": \"Course\",\n",
    "        \"contentType\": \"Course\",\n",
    "        \"creator\": \"Content Creator FMPS\",\n",
    "        \"primaryCategory\": \"Course\",\n",
    "        \"framework\": \"FMPS\",\n",
    "        \"organisationIds\": [\"fmps_organisation_fmps\"],\n",
    "        \"languageIds\": [\"fmps_language_arabic\"],\n",
    "        \"audience\": [\"Student\", \"Teacher\"],\n",
    "        \"targetlanguageIds\": [\"fmps_language_arabic\", \"fmps_language_french\"],\n",
    "        \"author\": \"John Doe\",\n",
    "        \"copyright\": \"FMPS\",\n",
    "        \"copyrightYear\": \"FMPS\",\n",
    "        \"license\": \"CC BY 4.0\",\n",
    "        \"additionalCategories\": [\"Digital Textbook\"],\n",
    "        \"hierarchy\": {}\n",
    "    }\n",
    "    \n",
    "    # Create modules and content mappings for the hierarchy\n",
    "    for module_code, module_info in course_info['modules'].items():\n",
    "        module_name = module_info['name']\n",
    "        content_ids = [content['doId'] for content in module_info['contents'] if content['doId']]\n",
    "        \n",
    "        # Add module to hierarchy with its content IDs\n",
    "        if content_ids:  # Only add modules with valid content\n",
    "            course_obj[\"hierarchy\"][module_name] = content_ids\n",
    "    \n",
    "    # Add course to courses array\n",
    "    courses_data.append(course_obj)\n",
    "\n",
    "# Save the transformed data to final.json\n",
    "with open('final.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(courses_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Courses data saved to final.json\")\n",
    "print(f\"Total courses: {len(courses_data)}\")\n",
    "print(f\"Sample course structure:\")\n",
    "if courses_data:\n",
    "    sample_course = courses_data[0]\n",
    "    print(f\"- Name: {sample_course['name']}\")\n",
    "    print(f\"- Modules: {len(sample_course['hierarchy'])}\")\n",
    "    for module_name, content_ids in list(sample_course['hierarchy'].items())[:2]:\n",
    "        print(f\"  - {module_name}: {len(content_ids)} contents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb1310",
   "metadata": {},
   "source": [
    "## Verification for Node.js Scripts\n",
    "\n",
    "The `final.json` file is now structured to match the format expected by the Node.js scripts (`1.app.js`, `2.herc.js`, and `3.revPub.js`). This format includes:\n",
    "\n",
    "1. An array of course objects\n",
    "2. Each course having the required metadata fields\n",
    "3. A hierarchy property that maps module names to content IDs\n",
    "\n",
    "This structure allows the Node.js scripts to:\n",
    "- Create courses and modules via the API\n",
    "- Establish hierarchical relationships\n",
    "- Perform review and publishing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Verify compatibility with courses.json format\n",
    "try:\n",
    "    import os\n",
    "    courses_ref_path = os.path.join('..', 'courses.json')\n",
    "    \n",
    "    if os.path.exists(courses_ref_path):\n",
    "        with open(courses_ref_path, 'r', encoding='utf-8') as f:\n",
    "            reference_courses = json.load(f)\n",
    "            \n",
    "        print(f\"Reference courses.json contains {len(reference_courses)} courses\")\n",
    "        print(f\"Our final.json contains {len(courses_data)} courses\")\n",
    "        \n",
    "        # Compare structure of first course\n",
    "        if reference_courses and courses_data:\n",
    "            ref_keys = set(reference_courses[0].keys())\n",
    "            our_keys = set(courses_data[0].keys())\n",
    "            \n",
    "            print(\"\\nKey comparison:\")\n",
    "            print(f\"Keys in reference but not in ours: {ref_keys - our_keys}\")\n",
    "            print(f\"Keys in ours but not in reference: {our_keys - ref_keys}\")\n",
    "            print(f\"Common keys: {len(ref_keys.intersection(our_keys))}\")\n",
    "            \n",
    "            print(\"\\nHierarchy format:\")\n",
    "            print(f\"Reference format: {type(reference_courses[0]['hierarchy'])}\")\n",
    "            print(f\"Our format: {type(courses_data[0]['hierarchy'])}\")\n",
    "    else:\n",
    "        print(\"Reference courses.json file not found for comparison\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during verification: {e}\")\n",
    "    \n",
    "print(\"\\nThe final.json file is ready for use with the Node.js scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy final.json to the parent directory for easy access by Node.js scripts\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    parent_dir = os.path.join('..', 'final.json')\n",
    "    shutil.copy('final.json', parent_dir)\n",
    "    print(f\"Copied final.json to {os.path.abspath(parent_dir)} for use by Node.js scripts\")\n",
    "except Exception as e:\n",
    "    print(f\"Error copying file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
